# Simulation parameters
simulation:
  verbose: 1            # 0 = None, 1 = run-level, 2 = organizational step level, 3 = move-level
  log: false            # log all output (set to false when testing)
  vizLearning: false    # visualize Q-value back-propagation?
  bucket: true          # save to bucket?

# Learning parameters for the Dyna agent
dyna:
  episodes: 100 # default: 1000
  runs: 50    # default: 5000 (runtime at 5000 ~ 14 hours)
  gamma: 0.9     # discount (default: 0.9)
  planning: 4    # number of planning steps for indirect learning (default: 4)
  epsilon: 0.1   # exploration rate (default: 0.1)
  alpha: 0.3     # learning rate (default: 0.3)
  nu: 0.35       # scalar for learning rate (default: 0.35)
  lambda: 2      # specialization (1, 2 or 4)
  tau: 0         # automation (default: 0)
  kappa: 0       # time-based weight for model learning (default: 0)
  phi: 0.5       # coordination cost share under automation (default: 0.5)
  omega: 0       # transition costs of entering or exiting automation (default: 0)

# Maze parameters
maze:
  moveCost: 1   # costs to make a move (default: 1)
  movesExploit: 11
  movesExplore: 7
  delta: 0      # frequency of environmental change
  eta: 0.9      # coordination cost scalar (default: 0.9)
  initDoor: half  # "closed" or "random" or "half" (default: half)
  doorSwitching: intervals  # "random" or "intervals" (default: intervals)
  startState: [6, 6]
  conditionalBanditStates:
    - [3, 6]
    - [9, 6]
    - [6, 3]
    - [6, 9]
  doorStates:
    - [2, 4]  # domain 1
    - [10, 8] # domain 2
    - [8, 2]  # domain 3
    - [4, 10] # domain 4
  goalStates:
    - [1, 4]  # domain 1
    - [11, 8] # domain 2
    - [8, 1]  # domain 3
    - [4, 11] # domain 4
  wallStates:
    - [ 0, 0 ]
    - [ 0, 1 ]
    - [ 0, 2 ]
    - [ 0, 3 ]
    - [ 0, 4 ]
    - [ 0, 5 ]
    - [ 0, 6 ]
    - [ 0, 7 ]
    - [ 0, 8 ]
    - [ 0, 9 ]
    - [ 0, 10 ]
    - [ 0, 11 ]
    - [ 0, 12 ]
    - [ 1, 0 ]
    - [ 1, 1 ]
    - [ 1, 2 ]
    - [ 1, 3 ]
    - [ 1, 9 ]
    - [ 1, 10 ]
    - [ 1, 11 ]
    - [ 1, 12 ]
    - [ 2, 0 ]
    - [ 2, 1 ]
    - [ 2, 2 ]
    - [ 2, 3 ]
    - [ 2, 5 ]
    - [ 2, 6 ]
    - [ 2, 7 ]
    - [ 2, 9 ]
    - [ 2, 10 ]
    - [ 2, 11 ]
    - [ 2, 12 ]
    - [ 3, 0 ]
    - [ 3, 1 ]
    - [ 3, 2 ]
    - [ 3, 3 ]
    - [ 3, 9 ]
    - [ 3, 10 ]
    - [ 3, 11 ]
    - [ 3, 12 ]
    - [ 4, 0 ]
    - [ 4, 4 ]
    - [ 4, 5 ]
    - [ 4, 7 ]
    - [ 4, 8 ]
    - [ 4, 12 ]
    - [ 5, 0 ]
    - [ 5, 2 ]
    - [ 5, 4 ]
    - [ 5, 5 ]
    - [ 5, 7 ]
    - [ 5, 8 ]
    - [ 5, 10 ]
    - [ 5, 12 ]
    - [ 6, 0 ]
    - [ 6, 2 ]
    - [ 6, 10 ]
    - [ 6, 12 ]
    - [ 7, 0 ]
    - [ 7, 2 ]
    - [ 7, 4 ]
    - [ 7, 5 ]
    - [ 7, 7 ]
    - [ 7, 8 ]
    - [ 7, 10 ]
    - [ 7, 12 ]
    - [ 8, 0 ]
    - [ 8, 4 ]
    - [ 8, 5 ]
    - [ 8, 7 ]
    - [ 8, 8 ]
    - [ 8, 12 ]
    - [ 9, 0 ]
    - [ 9, 1 ]
    - [ 9, 2 ]
    - [ 9, 3 ]
    - [ 9, 9 ]
    - [ 9, 10 ]
    - [ 9, 11 ]
    - [ 9, 12 ]
    - [ 10, 0 ]
    - [ 10, 1 ]
    - [ 10, 2 ]
    - [ 10, 3 ]
    - [ 10, 5 ]
    - [ 10, 6 ]
    - [ 10, 7 ]
    - [ 10, 9 ]
    - [ 10, 10 ]
    - [ 10, 11 ]
    - [ 10, 12 ]
    - [ 11, 0 ]
    - [ 11, 1 ]
    - [ 11, 2 ]
    - [ 11, 3 ]
    - [ 11, 9 ]
    - [ 11, 10 ]
    - [ 11, 11 ]
    - [ 11, 12 ]
    - [ 12, 0 ]
    - [ 12, 1 ]
    - [ 12, 2 ]
    - [ 12, 3 ]
    - [ 12, 4 ]
    - [ 12, 5 ]
    - [ 12, 6 ]
    - [ 12, 7 ]
    - [ 12, 8 ]
    - [ 12, 9 ]
    - [ 12, 10 ]
    - [ 12, 11 ]
    - [ 12, 12 ]
  explorationStates:
    - [3, 5] # domain 1
    - [3, 4]
    - [2, 4]
    - [9, 7] # domain 2
    - [9, 8]
    - [10, 8]
    - [7, 3] # domain 3
    - [8, 3]
    - [8, 2]
    - [5, 9] # domain 4
    - [4, 9]
    - [4, 10]
  neutralStates:
    - [6, 6] # start
    - [5, 6] # domain 1
    - [4, 6]
    - [3, 6]
    - [7, 6] # domain 2
    - [8, 6]
    - [9, 6]
    - [6, 5] # domain 3
    - [6, 4]
    - [6, 3]
    - [6, 7] # domain 4
    - [6, 8]
    - [6, 9]

